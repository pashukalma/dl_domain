{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Enhanced version of Unet"
      ],
      "metadata": {
        "id": "k9vM5TLpLL-I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5tXce6Sz5C2"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Monai Unet supports residual units and the hyperparameters\n",
        "Unet has some constraints with the input sizes\n",
        "\n",
        "For our use cases we define UNet structure\n",
        "\n",
        "model = UNet(\n",
        "    spatial_dims=3,\n",
        "    in_channels=1,\n",
        "    out_channels=2,\n",
        "    channels=(16, 32, 64, 128, 256),\n",
        "    strides=(2, 2, 2, 2),\n",
        "    num_res_units=2,\n",
        "    norm=Norm.BATCH).to(device)\n",
        "\n",
        "\n",
        "-->16x80x80                                       up\n",
        "      |                                         |-->\n",
        "      -->32x40x40                             up\n",
        "          |                                |-->\n",
        "          -->64x20x20                     up\n",
        "                |                      |-->\n",
        "                -->128x10x10          up\n",
        "                      |               |\n",
        "                      -->256x5x5 --->\n",
        "\n",
        "Residual Unit:  (Conv2D +Stride) + (Instance Norm) + (PReLU) +\n",
        "                (Conv2D) + (Instance Norm) + (PReLU)\n",
        "UpSample:       (ConvTrans2D +Stride) + (Concat) +\n",
        "                (Cond2D) + (Instance Norm) + (PReLU)\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -c \"import monai\" || pip install -q \"monai-weekly\""
      ],
      "metadata": {
        "id": "sH4OeUQSM4L-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import monai\n",
        "from monai.networks.nets import UNet\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "'''\n",
        "Define Structure with res units 0 and no impact on input size\n",
        "1st down layer - intermediate skip connection - final up layer\n",
        "'''\n",
        "unet_model_0 = UNet(\n",
        "    spatial_dims=3,\n",
        "    in_channels=1,\n",
        "    out_channels=1,\n",
        "    channels=(8, 16, 32),\n",
        "    strides=(2, 3),\n",
        "    kernel_size=3,\n",
        "    up_kernel_size=3,\n",
        "    num_res_units=0,\n",
        ")\n",
        "unet_model_0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBbqq_v7z8Tv",
        "outputId": "693f1065-eaed-4b2b-deca-559cd9a9d257"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "UNet(\n",
              "  (model): Sequential(\n",
              "    (0): Convolution(\n",
              "      (conv): Conv3d(1, 8, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
              "      (adn): ADN(\n",
              "        (N): InstanceNorm3d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "        (D): Dropout(p=0.0, inplace=False)\n",
              "        (A): PReLU(num_parameters=1)\n",
              "      )\n",
              "    )\n",
              "    (1): SkipConnection(\n",
              "      (submodule): Sequential(\n",
              "        (0): Convolution(\n",
              "          (conv): Conv3d(8, 16, kernel_size=(3, 3, 3), stride=(3, 3, 3), padding=(1, 1, 1))\n",
              "          (adn): ADN(\n",
              "            (N): InstanceNorm3d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "            (D): Dropout(p=0.0, inplace=False)\n",
              "            (A): PReLU(num_parameters=1)\n",
              "          )\n",
              "        )\n",
              "        (1): SkipConnection(\n",
              "          (submodule): Convolution(\n",
              "            (conv): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "            (adn): ADN(\n",
              "              (N): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "              (D): Dropout(p=0.0, inplace=False)\n",
              "              (A): PReLU(num_parameters=1)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (2): Convolution(\n",
              "          (conv): ConvTranspose3d(48, 8, kernel_size=(3, 3, 3), stride=(3, 3, 3), padding=(1, 1, 1), output_padding=(2, 2, 2))\n",
              "          (adn): ADN(\n",
              "            (N): InstanceNorm3d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "            (D): Dropout(p=0.0, inplace=False)\n",
              "            (A): PReLU(num_parameters=1)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (2): Convolution(\n",
              "      (conv): ConvTranspose3d(16, 1, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "for a deeper UNet the intermediate block is expanded\n",
        "two modules are needed Convolutions and Skip Connections\\\n",
        "each with four layers: Activation (PReLU), Droput, Norm (InstanceNorm3d),\n",
        "Convolution layers (Conv and ConvTranspose)\n",
        "\n",
        "For Convolution layers, the output size depends on stride, kernel_size, dilation,\n",
        "padding.\n",
        "For our UNet, dilation = 1, and padding = (kernel_size -1)/2\n",
        "The output size of Conv. is math.floor((input_size + stride -1) / stride)\n",
        "\n",
        "Output size for ConvTranspose layer is input_size * stride\n",
        "\n",
        "InUNet, SkipConnection is called via\n",
        "nn.Sequential(down, SkipConnection(subblock), up) and line be called in forward\n",
        "function, torch.cat([x, self.submodule(x)], dim=1)\n",
        "\n",
        "Constraints of UNet\n",
        "'''"
      ],
      "metadata": {
        "id": "G2c0Ui9_z8bV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' Conv Layer '''\n",
        "import math\n",
        "def get_conv_output_size(input_tensor, stride):\n",
        "  output_size = []\n",
        "  input_size = list(input_tensor.shape)[2:]\n",
        "  for size in input_size:\n",
        "    out = math.floor((size + stride -1) / stride)\n",
        "    output_size.append(out)\n",
        "  return output_size\n",
        "stride_value = 3\n",
        "input_tensor = torch.rand([1, 3, 1, 15, 29])\n",
        "get_conv_output_size(input_tensor, stride_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4fpzGM4Y9oY",
        "outputId": "647660df-14df-44f9-8ab6-51467053f122"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 5, 10]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = nn.Conv3d(in_channels=3, out_channels=1, stride=stride_value,\n",
        "                   kernel_size=3, padding=1)(input_tensor)\n",
        "output.shape[2:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypeUHrNtZkBw",
        "outputId": "7fd920da-ed0a-4892-89da-067a72af4711"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 5, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' ConvTranspose layer '''\n",
        "stride_value = 3\n",
        "[i* stride_value for i in input_tensor.shape[2:]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2BHoFnZZkFC",
        "outputId": "0dd0af40-27bd-499e-ef3c-f5c0ec5da591"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3, 45, 87]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = nn.ConvTranspose3d(\n",
        "    in_channels=3,\n",
        "    out_channels=1,\n",
        "    stride=stride_value,\n",
        "    kernel_size=3,\n",
        "    padding=1,\n",
        "    output_padding=stride_value -1,\n",
        ")(input_tensor)\n",
        "output.shape[2:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SH90DcjZkIV",
        "outputId": "dec124a5-6461-474c-c5f4-d2995fef9994"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 45, 87])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' Normalization layer '''\n",
        "list(monai.networks.layers.factories.Norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgU0aTEXbsj2",
        "outputId": "9e412bab-73e4-4fb4-cc9d-34b7bb27829d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('INSTANCE',\n",
              "  <function monai.networks.layers.factories.instance_factory(dim: 'int') -> 'type[nn.InstanceNorm1d | nn.InstanceNorm2d | nn.InstanceNorm3d]'>),\n",
              " ('BATCH',\n",
              "  <function monai.networks.layers.factories.batch_factory(dim: 'int') -> 'type[nn.BatchNorm1d | nn.BatchNorm2d | nn.BatchNorm3d]'>),\n",
              " ('INSTANCE_NVFUSER',\n",
              "  <function monai.networks.layers.factories.instance_nvfuser_factory(dim)>),\n",
              " ('GROUP',\n",
              "  <function monai.networks.layers.factories.LayerFactory.add_factory_class.<locals>.<lambda>(x=None)>),\n",
              " ('LAYER',\n",
              "  <function monai.networks.layers.factories.LayerFactory.add_factory_class.<locals>.<lambda>(x=None)>),\n",
              " ('LOCALRESPONSE',\n",
              "  <function monai.networks.layers.factories.LayerFactory.add_factory_class.<locals>.<lambda>(x=None)>),\n",
              " ('SYNCBATCH',\n",
              "  <function monai.networks.layers.factories.LayerFactory.add_factory_class.<locals>.<lambda>(x=None)>)]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' Batch normalization '''\n",
        "batch = nn.BatchNorm3d(num_features=3)\n",
        "for size in [[1, 3, 2, 1, 1], [2, 3, 1, 1, 1]]:\n",
        "  output = batch(torch.randn(size))\n",
        "#output, batch(torch.randn([1, 3, 2, 1, 1]))"
      ],
      "metadata": {
        "id": "wYW1NGWCbswm"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' Instance normalization '''\n",
        "instance = nn.InstanceNorm3d(num_features=3)\n",
        "for size in [[1, 3, 2, 1, 1], [1, 3, 1, 2, 1]]:\n",
        "  output = instance(torch.randn(size))\n",
        "#output.shape"
      ],
      "metadata": {
        "id": "Sjk2ApP3P-gT"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' Skip Connection '''"
      ],
      "metadata": {
        "id": "nmy4sL17dE1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Constraints of UNet\n",
        "\n",
        "1 down layer - 1 mode skip connection - 1 up layer\n",
        "- if len(channels) ==2, strides are single values\n",
        "- if using batch normalization B>1\n",
        "- if using local response normalization, no constraint\n",
        "- if using instance normalization, for d = max(H, W, D), then\n",
        "math.floor((d +s -1) / s ) >= 2, which means d >= s +1\n",
        "'''"
      ],
      "metadata": {
        "id": "kUFmC0G2dE5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' len(channels) = 2, batch norm '''\n",
        "network_model = UNet(\n",
        "    spatial_dims=3,\n",
        "    in_channels=1,\n",
        "    out_channels=3,\n",
        "    channels=(8, 16),\n",
        "    strides=(3,),\n",
        "    kernel_size=3,\n",
        "    up_kernel_size=3,\n",
        "    num_res_units=0,\n",
        "    norm=('batch')\n",
        ")\n",
        "input_tensor = torch.rand([2, 1, 1, 1, 1])\n",
        "network_model(input_tensor).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hcddNuyNqIs",
        "outputId": "c101bf02-78ab-46ff-869b-fb424b333d5c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3, 3, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' len(channels) = 2, localresponse '''\n",
        "network_model = UNet(\n",
        "    spatial_dims=3,\n",
        "    in_channels=1,\n",
        "    out_channels=3,\n",
        "    channels=(8, 16),\n",
        "    strides=(3,),\n",
        "    kernel_size=1,\n",
        "    up_kernel_size=1,\n",
        "    num_res_units=1,\n",
        "    norm=('localresponse', {'size': 1})\n",
        ")\n",
        "input_tensor = torch.rand([1, 1, 1, 1, 1])\n",
        "network_model(input_tensor).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3TyA3-SdFZg",
        "outputId": "df29a8ad-9502-4152-a766-0a1848e93408"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 3, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "network_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFmH4CD_LPyV",
        "outputId": "019c7d10-4719-4a3b-9420-edd3cb59eb5d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "UNet(\n",
              "  (model): Sequential(\n",
              "    (0): ResidualUnit(\n",
              "      (conv): Sequential(\n",
              "        (unit0): Convolution(\n",
              "          (conv): Conv3d(1, 8, kernel_size=(1, 1, 1), stride=(3, 3, 3))\n",
              "          (adn): ADN(\n",
              "            (N): LocalResponseNorm(1, alpha=0.0001, beta=0.75, k=1.0)\n",
              "            (D): Dropout(p=0.0, inplace=False)\n",
              "            (A): PReLU(num_parameters=1)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (residual): Conv3d(1, 8, kernel_size=(1, 1, 1), stride=(3, 3, 3))\n",
              "    )\n",
              "    (1): SkipConnection(\n",
              "      (submodule): ResidualUnit(\n",
              "        (conv): Sequential(\n",
              "          (unit0): Convolution(\n",
              "            (conv): Conv3d(8, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "            (adn): ADN(\n",
              "              (N): LocalResponseNorm(1, alpha=0.0001, beta=0.75, k=1.0)\n",
              "              (D): Dropout(p=0.0, inplace=False)\n",
              "              (A): PReLU(num_parameters=1)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (residual): Conv3d(8, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "      )\n",
              "    )\n",
              "    (2): Sequential(\n",
              "      (0): Convolution(\n",
              "        (conv): ConvTranspose3d(24, 3, kernel_size=(1, 1, 1), stride=(3, 3, 3), output_padding=(2, 2, 2))\n",
              "        (adn): ADN(\n",
              "          (N): LocalResponseNorm(1, alpha=0.0001, beta=0.75, k=1.0)\n",
              "          (D): Dropout(p=0.0, inplace=False)\n",
              "          (A): PReLU(num_parameters=1)\n",
              "        )\n",
              "      )\n",
              "      (1): ResidualUnit(\n",
              "        (conv): Sequential(\n",
              "          (unit0): Convolution(\n",
              "            (conv): Conv3d(3, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "          )\n",
              "        )\n",
              "        (residual): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' len(channels) = 2, instance norm '''\n",
        "network_model = UNet(\n",
        "    spatial_dims=3,\n",
        "    in_channels=1,\n",
        "    out_channels=3,\n",
        "    channels=(8, 16),\n",
        "    strides=(3,),\n",
        "    kernel_size=3,\n",
        "    up_kernel_size=5,\n",
        "    num_res_units=2,\n",
        "    norm='instance'\n",
        ")\n",
        "input_tensor = torch.rand([1, 1, 4, 1, 1])\n",
        "network_model(input_tensor).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2h321SGXdFdy",
        "outputId": "c50850aa-f7c7-412a-e45b-fd5501324f22"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 6, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Constraints of UNet - continued\n",
        "\n",
        "- if len(channels) >2, for input size [B, C, H, W, D]\n",
        "- if using instance normalization\n",
        "  size = math.floor((v + s[0] - 1) / s[0])\n",
        "'''"
      ],
      "metadata": {
        "id": "2ABBBatsjYO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' strides=(3,5), batch norm, batch_size >1 '''\n",
        "network_model = UNet(\n",
        "    spatial_dims=3,\n",
        "    in_channels=1,\n",
        "    out_channels=3,\n",
        "    channels=(8, 16, 32),\n",
        "    strides=(3, 5),\n",
        "    kernel_size=3,\n",
        "    up_kernel_size=3,\n",
        "    num_res_units=0,\n",
        "    norm='batch'\n",
        ")\n",
        "input_tensor = torch.rand([2, 1, 13, 14, 15])\n",
        "network_model(input_tensor).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcOhshrnjb3E",
        "outputId": "0dcb504f-5a50-4aeb-fe3c-adfcf17fc7bc"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3, 15, 15, 15])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "strides=(3, 2, 4), localresponse,\n",
        "math.floor((v+2) /3) should be 8*k, v in [22, 23, 2]\n",
        "'''\n",
        "network_model = UNet(\n",
        "    spatial_dims=3,\n",
        "    in_channels=1,\n",
        "    out_channels=3,\n",
        "    channels=(8, 16, 32, 16),\n",
        "    strides=(3, 2, 4),\n",
        "    kernel_size=1,\n",
        "    up_kernel_size=3,\n",
        "    num_res_units=10,\n",
        "    norm=('localresponse', {'size': 1})\n",
        ")\n",
        "input_tensor = torch.rand([1, 1, 22, 23, 24])\n",
        "network_model(input_tensor).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TS7pkXRTjb7x",
        "outputId": "ac7d657b-53e7-4248-c640-0139d79152e5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 24, 24, 24])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l-RQwi1ujcTW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}