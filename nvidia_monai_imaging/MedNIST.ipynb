{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Medical Image Classification with MedNIST Dataset**"
      ],
      "metadata": {
        "id": "A0dpRtL57CNT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "End-to-End training and evaluation based on the MedNIST dataset\n",
        "- Create the dataset and use Transforms to preprocess the images data\n",
        "- Use DenseNet (Monai) for classification\n",
        "- Train the model with PyTorch and evaluate on test dataset."
      ],
      "metadata": {
        "id": "aJ-z8lAbvZdW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install monai\n",
        "!pip install monai-weekly\n",
        "!pip install ignite\n",
        "!python -c \"import monai; print(monai.__version__)\"\n",
        "!python -c \"import monai\" || pip install -q \"monai-weekly[nibabel, ignite, pillow, tqdm]\"\n",
        "!python -c \"import matplotlib\" || pip install -q matplotlib\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lS4aziAr-HCK",
        "outputId": "06f587bc-67f6-47da-e271-b96ae40ba000"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed monai-1.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, shutil, tempfile, PIL, logging, sys\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "from monai.apps import download_and_extract\n",
        "from monai.data import decollate_batch, DataLoader\n",
        "from monai.metrics import ROCAUCMetric\n",
        "from monai.networks.nets import DenseNet121, densenet121\n",
        "from monai.config import print_config\n",
        "from monai.transforms import ( Activations, EnsureChannelFirst, AsDiscrete, Compose,\n",
        "    LoadImage, RandFlip, RandRotate, RandZoom, ScaleIntensity,)\n",
        "from monai.utils import set_determinism\n",
        "from monai.engines import SupervisedTrainer\n",
        "from monai.handlers import StatsHandler\n",
        "from monai.inferers import SimpleInferer\n",
        "from monai.networks import eval_mode\n",
        "print_config()\n",
        "\n",
        "!mkdir monai\n",
        "os.environ['monai'] = '/content/monai'\n",
        "dir = os.environ.get('monai')\n",
        "rootdir = tempfile.mkdtemp() if dir is None else dir\n",
        "rootdir"
      ],
      "metadata": {
        "id": "mQdau0608Sq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' MedNIST dataset gathers several sets, X-ray datasets '''\n",
        "resource = \"https://github.com/Project-MONAI/MONAI-extra-test-data/releases/download/0.8.1/MedNIST.tar.gz\"\n",
        "md5 = \"0bc7306e7427e00ad1c5526a6677552d\"\n",
        "compressed_file = os.path.join(rootdir, \"MedNIST.tar.gz\")\n",
        "datadir = os.path.join(rootdir, \"MedNIST\")\n",
        "download_and_extract(resource, compressed_file, rootdir, md5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjEWq-yJ81Ci",
        "outputId": "d0a91978-bf89-4fe9-ca26-6ace7f76bb6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MedNIST.tar.gz: 59.0MB [00:03, 18.4MB/s]                            "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-06-28 14:21:05,571 - INFO - Downloaded: /content/monai/MedNIST.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-06-28 14:21:05,678 - INFO - Verified 'MedNIST.tar.gz', md5: 0bc7306e7427e00ad1c5526a6677552d.\n",
            "2025-06-28 14:21:05,679 - INFO - Writing into directory: /content/monai.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' seed/deterministic training for reproduceability '''\n",
        "set_determinism(seed=0)"
      ],
      "metadata": {
        "id": "pnT91ACf8S3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#rm -rf  monai/MedNIST/README.md"
      ],
      "metadata": {
        "id": "axvW6AdTaNiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' read images from folders '''\n",
        "class_names = sorted(os.listdir(datadir))\n",
        "num_classes = len(class_names)\n",
        "imgfiles = [\n",
        "  [os.path.join(datadir, class_names[i], x)\n",
        "    for x in os.listdir(os.path.join(datadir, class_names[i]))]\n",
        "      for i in range(num_classes)\n",
        "]\n",
        "class_names, num_classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmyacLnb8S6i",
        "outputId": "f6753969-fb6c-4272-982f-76de3ee18fea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['AbdomenCT', 'BreastMRI', 'CXR', 'ChestCT', 'Hand', 'HeadCT'], 6)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_each_folder = [len(imgfiles[i]) for i in range(num_classes)]\n",
        "imgfiles_lst = []\n",
        "image_class = []\n",
        "for i in range(num_classes):\n",
        "  imgfiles_lst.extend(imgfiles[i])\n",
        "  image_class.extend([i]* num_each_folder[i])\n",
        "num_total = len(image_class)\n",
        "image_width, image_height = PIL.Image.open(imgfiles_lst[0]).size\n",
        "num_each_folder, num_total, image_width, image_height\n",
        "print(f'total image count: {num_total}')\n",
        "print(f'labe; dimensions: {image_width}, {image_height}')\n",
        "print(f'label names: {class_names}')\n",
        "print(f'label counts: {num_each_folder}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvOABI-Y8S-H",
        "outputId": "9de7b465-b6ae-4251-a487-65e56a41a8e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total image count: 58954\n",
            "labe; dimensions: 64, 64\n",
            "label names: ['AbdomenCT', 'BreastMRI', 'CXR', 'ChestCT', 'Hand', 'HeadCT']\n",
            "label counts: [10000, 8954, 10000, 10000, 10000, 10000]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' training, validation, and test data list '''\n",
        "val_percent, test_percent = .1, .1\n",
        "length = len(imgfiles_lst)\n",
        "indices = np.arange(length)\n",
        "np.random.shuffle(indices)\n",
        "test_split = int(test_percent *length)\n",
        "val_split = int(val_percent *length) + test_split\n",
        "test_indices, val_indices = indices[:test_split], indices[test_split:val_split]\n",
        "train_indices = indices[val_split:]\n",
        "\n",
        "train_x = [imgfiles_lst[i] for i in train_indices]\n",
        "train_y = [image_class[i] for i in train_indices]\n",
        "val_x = [imgfiles_lst[i] for i in val_indices]\n",
        "val_y = [image_class[i] for i in val_indices]\n",
        "test_x = [imgfiles_lst[i] for i in test_indices]\n",
        "test_y = [image_class[i] for i in test_indices]"
      ],
      "metadata": {
        "id": "tJCsXgu_8TeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' transformations '''\n",
        "train_transforms = Compose([\n",
        "  LoadImage(image_only=True), EnsureChannelFirst(), ScaleIntensity(),\n",
        "  RandRotate(range_x=np.pi / 12, prob=0.5, keep_size=True),\n",
        "  RandFlip(spatial_axis=0, prob=0.5),\n",
        "])\n",
        "\n",
        "val_transforms = Compose(\n",
        "    [LoadImage(image_only=True), EnsureChannelFirst(), ScaleIntensity()])\n",
        "\n",
        "y_pred_trans = Compose([Activations(softmax=True)])\n",
        "y_trans = Compose([AsDiscrete(to_onehot=num_classes)])"
      ],
      "metadata": {
        "id": "vfo1EGr6IAik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MedDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, image_files, labels, transforms):\n",
        "    self.image_files = image_files\n",
        "    self.labels = labels\n",
        "    self.transforms = transforms\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.image_files)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.transforms(self.image_files[index]), self.labels[index]\n",
        "\n",
        "train_ds = MedDataset(train_x, train_y, train_transforms)\n",
        "train_loader = DataLoader(train_ds, batch_size=300, shuffle=True) #, num_workers=4)\n",
        "\n",
        "val_ds = MedDataset(val_x, val_y, val_transforms)\n",
        "val_loader = DataLoader(val_ds, batch_size=300, shuffle=True) #, num_workers=4)\n",
        "\n",
        "test_ds = MedDataset(test_x, test_y, val_transforms)\n",
        "test_loader = DataLoader(test_ds, batch_size=300, shuffle=True) #, num_workers=4)"
      ],
      "metadata": {
        "id": "iOiT8GRLIAfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' DenseNet121 Network and Optimizer '''\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else 'cpu'\n",
        "model = DenseNet121(spatial_dims=2, in_channels=1, out_channels=num_classes)\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), 1e-5)\n",
        "epochs = 5\n",
        "val_interval = 1\n",
        "auc = ROCAUCMetric()"
      ],
      "metadata": {
        "id": "rCK8wolgIAmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' Model Training '''\n",
        "best_metric=-1 ; best_metric_epoch=-1 ; epoch_loss_values=[] ; metric_values=[]\n",
        "for epoch in range(epochs):\n",
        "  model.train()\n",
        "  epochloss = 0 ; step = 0\n",
        "  for batch_data in train_loader:\n",
        "      step += 1\n",
        "      #inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n",
        "      inputs, labels = batch_data[0], batch_data[1]\n",
        "      optimizer.zero_grad()\n",
        "      outputs = model(inputs)\n",
        "      loss = loss_function(outputs, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      epochloss += loss.item()\n",
        "      epoch_len = len(train_ds) // train_loader.batch_size\n",
        "  epochloss/= step\n",
        "  epoch_loss_values.append(epochloss)\n",
        "  print(f'epoch {epoch +1} avg loss {epochloss:.4f}')\n",
        "\n",
        "  if (epoch +1) %val_interval ==0:\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      y_pred = torch.tensor([], dtype=torch.float32) #, device=device)\n",
        "      y = torch.tensor([], dtype=torch.long) #, device=device)\n",
        "      for val_data in val_loader:\n",
        "          val_images, val_labels = (\n",
        "              #val_data[0].to(device), val_data[1].to(device))\n",
        "              val_data[0], val_data[1])\n",
        "          y_pred = torch.cat([y_pred, model(val_images)], dim=0)\n",
        "          y = torch.cat([y, val_labels], dim=0)\n",
        "      y_onehot = [y_trans(i) for i in decollate_batch(y, detach= False)]\n",
        "      y_pred_act = [y_pred_trans(i) for i in decollate_batch(y_pred)]\n",
        "      auc(y_pred_act, y_onehot)\n",
        "      result = auc.aggregate()\n",
        "      auc.reset()\n",
        "      del y_pred_act, y_onehot\n",
        "      metric_values.append(result)\n",
        "      acc_value = torch.eq(y_pred.argmax(dim=1), y)\n",
        "      acc_metric = acc_value.sum().item() / len(acc_value)\n",
        "      if result > best_metric:\n",
        "        best_metric = result\n",
        "        best_metric_epoch = epoch +1\n",
        "        torch.save(model.state_dict(),\n",
        "                   os.path.join(rootdir, 'best_metric_model.pth'))\n",
        "\n",
        "print(f'train completed, best metric: {best_metric:.4f} at epoch {best_metric_epoch}')"
      ],
      "metadata": {
        "id": "U6-9NAS_7gNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' Model evaluation on test Dataset '''\n",
        "model.load_state_dict(torch.load(os.path.join(rootdir, 'best_metric_model.pth')))\n",
        "model.eval()\n",
        "y_true, y_pred= [], []\n",
        "with torch.no_grad():\n",
        "  for test_data in test_loader:\n",
        "    test_images, test_labels = (\n",
        "        #test_data[0].to(device), test_data[0].to(device))\n",
        "        test_data[0], test_data[0])\n",
        "    pred = model(test_images).argmax(dim=1)\n",
        "    for i in range(len(pred)):\n",
        "        y_true.append(test_labels[i].item())\n",
        "        y_pred.append(pred[i].item())\n",
        "classification_report(y_true, y_pred, target_names = class_names)"
      ],
      "metadata": {
        "id": "7BaSnJsYN5F8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MedNIST with DenseNet-121 and Supervised Training workflow**"
      ],
      "metadata": {
        "id": "dYj8iT5lvMFS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from monai.transforms import (LoadImageD, EnsureChannelFirstD, ScaleIntensityD)\n",
        "transform = Compose([\n",
        "\tLoadImageD(keys=\"image\", image_only=True),\n",
        "\tEnsureChannelFirstD(keys=\"image\"),\n",
        "\tScaleIntensityD(keys=\"image\"),])"
      ],
      "metadata": {
        "id": "0EDOXGpBxAeJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from monai.apps import MedNISTDataset\n",
        "dataset = MedNISTDataset(\n",
        "    root_dir=rootdir, transform=transform, section='training', download=True)"
      ],
      "metadata": {
        "id": "vQflHYgWveK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' Network and Supervisor Training '''\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else 'cpu'\n",
        "max_epochs =5\n",
        "model = densenet121(spatial_dims=2, in_channels=1, out_channels=6).to(device)\n",
        "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
        "\n",
        "trainer = SupervisedTrainer(\n",
        "    device = torch.device('cuda:0'),\n",
        "    max_epochs = max_epochs,\n",
        "    train_data_loader = DataLoader(dataset, batch_size=512, shuffle=True),\n",
        "    network = model,\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-5),\n",
        "    loss_function = torch.nn.CrossEntropyLoss(),\n",
        "    inferer = SimpleInferer(),\n",
        "    train_handlers = StatsHandler()\n",
        ")"
      ],
      "metadata": {
        "id": "Zi4bp3xmDDmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.run()"
      ],
      "metadata": {
        "id": "gunKh2tlyQk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "dataset_dir = Path(rootdir, 'MedNIST')\n",
        "class_names = sorted(f'{x.name}' for x in dataset_dir.iterdir() if x.is_dir)\n",
        "testdata = MedNISTDataset(root_dir=rootdir, transform=transform,\n",
        "      section=\"test\", download=False, runtime_cache=True)\n",
        "class_names, next(iter(testdata))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOs_kn85yQo1",
        "outputId": "7f86a34e-9665-4c87-b4fb-5eb86d46dc6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['AbdomenCT', 'BreastMRI', 'CXR', 'ChestCT', 'Hand', 'HeadCT', 'README.md'],\n",
              " {'image': metatensor([[[0.1250, 0.1250, 0.1250,  ..., 0.1193, 0.1250, 0.1250],\n",
              "           [0.1250, 0.1250, 0.1250,  ..., 0.1136, 0.1250, 0.1307],\n",
              "           [0.1250, 0.1250, 0.1250,  ..., 0.1080, 0.1193, 0.1364],\n",
              "           ...,\n",
              "           [0.1250, 0.1250, 0.1250,  ..., 0.1875, 0.1250, 0.1136],\n",
              "           [0.1250, 0.1250, 0.1250,  ..., 0.1477, 0.1250, 0.1250],\n",
              "           [0.1250, 0.1250, 0.1250,  ..., 0.1193, 0.1250, 0.1307]]]),\n",
              "  'label': 0,\n",
              "  'class_name': 'AbdomenCT'})"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_items = 10\n",
        "with eval_mode(model):\n",
        "  for item in DataLoader(testdata, batch_size=1,num_workers=0):\n",
        "    prob = np.array(model(item['image'].to(device)).detach().to('cpu'))[0]\n",
        "    pred = class_names[prob.argmax()]\n",
        "    gt = item['class_name'][0]\n",
        "    print(f'class prediction is {pred}. ground-truth: {gt}')\n",
        "    max_items -= 1\n",
        "    if max_items == 0:\n",
        "      break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnjbBjviIgFM",
        "outputId": "f9896702-0c13-43e2-8a2a-a91f35133637"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class prediction is AbdomenCT. ground-truth: AbdomenCT\n",
            "class prediction is BreastMRI. ground-truth: BreastMRI\n",
            "class prediction is ChestCT. ground-truth: ChestCT\n",
            "class prediction is CXR. ground-truth: CXR\n",
            "class prediction is Hand. ground-truth: Hand\n",
            "class prediction is HeadCT. ground-truth: HeadCT\n",
            "class prediction is HeadCT. ground-truth: HeadCT\n",
            "class prediction is CXR. ground-truth: CXR\n",
            "class prediction is ChestCT. ground-truth: ChestCT\n",
            "class prediction is BreastMRI. ground-truth: BreastMRI\n"
          ]
        }
      ]
    }
  ]
}