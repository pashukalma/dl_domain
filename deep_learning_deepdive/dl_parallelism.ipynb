{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wnd_-nWmWlS2"
      },
      "outputs": [],
      "source": [
        "import os, subprocess\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cpu_():\n",
        "  return torch.device('cpu')\n",
        "def gpu_():\n",
        "  return torch.device('cuda')\n",
        "def gpu_(i=0):\n",
        "  return torch.device(f'cuda:{i}')\n",
        "def num_gpu():\n",
        "  return torch.cuda.device_count()\n",
        "def try_gpu(i=0):\n",
        "  if torch.cuda.device_count() >=i +1:\n",
        "    return gpu_(i)\n",
        "  return cpu_()\n",
        "\n",
        "device_ = torch.device('cuda') if torch.cuda.is_available() else 'cpu'\n",
        "device_, gpu_(), torch.cuda.device_count(), try_gpu(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsq6DzdOYnrN",
        "outputId": "205d9ca0-fc4e-4882-f5ff-720fc380d4e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(device(type='cuda'),\n",
              " device(type='cuda', index=0),\n",
              " 1,\n",
              " device(type='cuda', index=0))"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.randn(size=(3, 3), device=device_)\n",
        "b = torch.mm(a, a)\n",
        "a.shape, a, b.shape, b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nay-xu9cYn0O",
        "outputId": "b9801bba-e6e4-414e-e838-a864056a7532"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3, 3]),\n",
              " tensor([[ 1.1504, -0.5589,  1.1304],\n",
              "         [ 1.9525, -0.5406,  0.0241],\n",
              "         [ 0.5134,  0.0660, -1.1161]], device='cuda:0'),\n",
              " torch.Size([3, 3]),\n",
              " tensor([[ 0.8124, -0.2663,  0.0253],\n",
              "         [ 1.2030, -0.7975,  2.1673],\n",
              "         [ 0.1464, -0.3962,  1.8276]], device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Asynchronous Computation**"
      ],
      "metadata": {
        "id": "DnUdSYxoi9SS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "class Timer:\n",
        "  def __init__(self):\n",
        "    self.times = []\n",
        "    self.start()\n",
        "  def start(self):\n",
        "    self.tstart = time.time()\n",
        "  def stop(self):\n",
        "    self.times.append(time.time() - self.tstart)\n",
        "    return self.times[-1]"
      ],
      "metadata": {
        "id": "t4pQaeMGe1s2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Benchmark:\n",
        "  def __init__(self, desc='Complete'):\n",
        "    self.desc = desc\n",
        "  def __enter__(self):\n",
        "    self.timer = Timer()\n",
        "    return self\n",
        "  def __exit__(self, *args):\n",
        "    print(f'{self.desc}: {self.timer.stop():.4f} sec')"
      ],
      "metadata": {
        "id": "8PRB934IYn5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with Benchmark('numpy'):\n",
        "  for _ in range(5):\n",
        "    a = np.random.normal(size=(1000, 1000))\n",
        "    b = np.dot(a, a)\n",
        "\n",
        "with Benchmark('torch'):\n",
        "  for _ in range(5):\n",
        "    a = torch.randn(size=(1000, 1000))\n",
        "    b = torch.mm(a, a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8ONbkI9fbnu",
        "outputId": "3d519614-a785-4924-d6f2-ed0530dc3028"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numpy: 0.2732 sec\n",
            "torch: 0.1974 sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' this is much faster in orderes of magnitude with PyTorch\n",
        "by default GPU ops areasynchronous\n",
        "the backend manages ts own threads that continually select and execute '''\n",
        "with Benchmark('torch - synchronize'):\n",
        "  for _ in range(5):\n",
        "    a = torch.randn(size=(10000, 10000))\n",
        "    b = torch.mm(a, a)\n",
        "  torch.cuda.synchronize(device_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlZF3w3Mfbkh",
        "outputId": "f3ca6095-3332-4e69-f2f2-a02d245b9fc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch - synchronize: 24.8038 sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones((1, 2), device = device_)\n",
        "y = torch.ones((1, 2), device = device_)\n",
        "z = x *y +2\n",
        "z"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5q_flhQueCRz",
        "outputId": "7cae5bb6-9a24-414d-f270-fd6f20d6812c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3., 3.]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Parallel computation on GPUs**"
      ],
      "metadata": {
        "id": "Ul1n2hHilR-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try_gpu()\n",
        "def run(x):\n",
        "  return [x.mm(x) for _ in range(5)]"
      ],
      "metadata": {
        "id": "Y3KwTiVdeCU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' configuration with more than one GPU to perform\n",
        "matrix-matrix calculations on device using data into two variables '''\n",
        "x_gpu1 = torch.rand(size=(1000, 1000), device=try_gpu(i=0))\n",
        "run(x_gpu1)\n",
        "torch.cuda.synchronize(try_gpu(i=0))\n",
        "with Benchmark('GPU1 time'):\n",
        "  run(x_gpu1)\n",
        "  torch.cuda.synchronize(try_gpu(i=0))\n",
        "'''\n",
        "x_gpu2 = torch.rand(size=(100, 100), device=try_gpu(i=1))\n",
        "run(x_gpu2)\n",
        "torch.cuda.synchronize(try_gpu(i=1))\n",
        "with Benchmark('GPU2 time'):\n",
        "  run(x_gpu2)\n",
        "  torch.cuda.synchronize(try_gpu(i=1))\n",
        "''' ;"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-7oT-oqeCX5",
        "outputId": "5f6cb460-f4ff-4990-b823-212a68427010"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU1 time: 0.0039577484130859375 sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try_gpu(i=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcblNa3tndEt",
        "outputId": "86853a23-1e8e-439a-c6b0-668fd42deeb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Parallel Communication and Computation**"
      ],
      "metadata": {
        "id": "Ohw0tRz3oW5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def move_to_cpu(x, non_blocking=False):\n",
        "  return [y.to('cpu',  non_blocking=non_blocking) for y in x]\n",
        "\n",
        "with Benchmark('run on GPU1 \\t\\t\\t'):\n",
        "  y = run(x_gpu1)\n",
        "  torch.cuda.synchronize()\n",
        "\n",
        "with Benchmark('copy/move to CPU \\t\\t'):\n",
        "  y_to_cpu = move_to_cpu(y)\n",
        "  torch.cuda.synchronize()\n",
        "\n",
        "with Benchmark('Run on GPU and copy to CPU\\t'):\n",
        "  y = run(x_gpu1)\n",
        "  y_to_cpu = move_to_cpu(y, True)\n",
        "  torch.cuda.synchronize()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRN4qfhnl2Tq",
        "outputId": "9c8afb3b-90e8-4178-83c0-c701bb2393cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run on GPU1 \t\t\t: 0.004096269607543945 sec\n",
            "copy/move to CPU \t\t: 0.014218568801879883 sec\n",
            "Run on GPU and copy to CPU\t: 0.005823850631713867 sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hardware**"
      ],
      "metadata": {
        "id": "0obInZAYp-m3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "processor/RAM/Ethernet/Expnasion bus (GPUs)/Storage with PCIbus\n",
        "Vectorization/Cache L1, L2 & L3/GPUs and Accelerators\n",
        "common latency numbers maintained on github/vemdor\n",
        "'''"
      ],
      "metadata": {
        "id": "bP3od2jpl2_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hybridize - Sequential class"
      ],
      "metadata": {
        "id": "vBq4Q-tyrJTk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mlp_network():\n",
        "  mlp_ = nn.Sequential(\n",
        "      nn.Linear(512, 256),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(256, 128),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(128, 2))\n",
        "  return mlp_\n",
        "x = torch.randn(size=(1, 512))\n",
        "mlp_ = mlp_network()\n",
        "mlp_(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SR3LtwWPl3Cv",
        "outputId": "6bda68dc-e707-478e-d22e-853cef2fb05a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1584,  0.1160]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlp__ = torch.jit.script(mlp_)\n",
        "mlp__(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDXelCu4rMZR",
        "outputId": "c12631f6-7f47-4835-c2da-0371984b4806"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1584,  0.1160]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_net = mlp_network()\n",
        "with Benchmark('not using torchscript \\t'):\n",
        "  for _ in range(1000): mlp_net(x)\n",
        "\n",
        "mlp_net_jit = torch.jit.script(mlp_net)\n",
        "with Benchmark('using torchscript \\t'):\n",
        "  for _ in range(1000): mlp_net_jit(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLwvU_WArMmz",
        "outputId": "ff9df4b8-06ec-4269-e1f8-cc7028361604"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "not using torchscript \t: 0.0739 sec\n",
            "using torchscript \t: 0.0595 sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Serialization**"
      ],
      "metadata": {
        "id": "7wh8PK18uCMO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_net_jit.save('my_mlp')\n",
        "!ls -lh my_mlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Us2Hja0stQuc",
        "outputId": "5db27211-3c3f-4863-8781-ae1ff4a4eb44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 652K Jun 11 16:00 my_mlp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Multiple-GPUs**"
      ],
      "metadata": {
        "id": "CfhXap1GuTDV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' dataset/dataloader '''\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "\n",
        "from torchvision.transforms import transforms\n",
        "transformations = [transforms.ToTensor()]\n",
        "transformations = transforms.Compose(transformations)\n",
        "train_set = datasets.FashionMNIST(\n",
        "    root='/content/', train=True, transform=transformations, download=True)\n",
        "test_set = datasets.FashionMNIST(\n",
        "    root='/content/', train=False, transform=transformations, download=True)\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    train_set, batch_size=32, shuffle=True, num_workers=2)\n",
        "test_dataloader = torch.utils.data.DataLoader(\n",
        "    test_set, batch_size=32, shuffle=False, num_workers=2)\n",
        "next(iter(train_dataloader))[0], next(iter(test_dataloader))[0]\n",
        "len(train_dataloader), len(test_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CLADaMG8f73",
        "outputId": "0f7fabe7-0dd2-4cac-ffd3-d4b77d488f8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:01<00:00, 19.2MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 307kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:00<00:00, 5.62MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 14.1MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1875, 313)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Residual(nn.Module):\n",
        "  def __init__(self, num_channels, use_1x1conv=False, strides=1):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.LazyConv2d(num_channels, kernel_size=3, padding=1, stride=strides)\n",
        "    self.conv2 = nn.LazyConv2d(num_channels, kernel_size=3, padding=1)\n",
        "    if use_1x1conv:\n",
        "      self.conv3 = nn.LazyConv2d(num_channels, kernel_size=1, stride=strides)\n",
        "    else:\n",
        "      self.conv3 = None\n",
        "    self.batch_norm1 = nn.LazyBatchNorm2d()\n",
        "    self.batch_norm2 = nn.LazyBatchNorm2d()\n",
        "\n",
        "  def forward(self, X):\n",
        "    Y = nn.ReLU(self.batch_norm1(self.conv1(X)))\n",
        "    Y = self.batch_norm2(self.conv2(Y))\n",
        "    if self.conv3:\n",
        "      X = self.conv3(X)\n",
        "    Y += X\n",
        "    return nn.ReLU(Y)"
      ],
      "metadata": {
        "id": "ryPhRMONwPsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' Demo Network for Parallelization in Training '''\n",
        "def my_resnet(num_classes, in_channels =1):\n",
        "  def resnet_block(in_channels, out_channels, num_residuals, first_blk=False):\n",
        "    blk = []\n",
        "    for i in range(num_residuals):\n",
        "      if i ==0 and not first_blk:\n",
        "        blk.append(Residual(out_channels, use_1x1conv=True))\n",
        "      else:\n",
        "        blk.append(Residual(out_channels))\n",
        "    return nn.Sequential(*blk)\n",
        "\n",
        "  network_ = nn.Sequential(\n",
        "      nn.Conv2d(in_channels, 64, kernel_size =1, stride=1, padding =1),\n",
        "      nn.BatchNorm2d(64), nn.ReLU())\n",
        "  network_.add_module('res-blk-1', resnet_block(64, 64, 2, first_blk=True))\n",
        "  network_.add_module('res-blk-2', resnet_block(64, 128, 2))\n",
        "  network_.add_module('res-blk-3', resnet_block(128, 126, 2))\n",
        "  network_.add_module('res-blk-4', resnet_block(256, 512, 2))\n",
        "  network_.add_module('global-avg-pool', nn.AdaptiveAvgPool2d((1, 1)))\n",
        "  network_.add_module(\n",
        "      'fc', nn.Sequential(nn.Flatten(), nn.Linear(512, num_classes)))\n",
        "  return network_"
      ],
      "metadata": {
        "id": "4Dyby8vMtQ3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "network = my_resnet(1, 10)"
      ],
      "metadata": {
        "id": "sV7jnR3ntQ7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' Training\n",
        "\n",
        "Training for parallelsim\n",
        "- network params initialized across devices\n",
        "- iterating over the mini batches they are to be divided across the devices\n",
        "- compute loss and gradients across devices\n",
        "- gradients aggregated and parameters updated\n",
        "\n",
        "Compute the accuracy in parallel to report the final performance of netwrk\n",
        "'''"
      ],
      "metadata": {
        "id": "W3N1SCBqDItV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(network, num_gpus, batch_size, lr):\n",
        "  train_iter, test_iter = train_dataloader\n",
        "  # devices = [try_gpu(i) for i in range(num_gpus)]\n",
        "  devices = try_gpu(i=0)\n",
        "  def init_weights(module):\n",
        "    if type(module) in [nn.Linear, nn.Conv2d]:\n",
        "      nn.init.normal_(module.weight, std=0.0)\n",
        "  network.apply(init_weights)\n",
        "  network = nn.DataParallel(network, device_ids = devices)\n",
        "  trainer = torch.optim.SGD(network.parameters(), lr)\n",
        "  loss = nn.CrossEntropyLoss()\n",
        "  timer, num_epochs = Timer(), 10\n",
        "  # visualize with 'epoch', 'test acc'\n",
        "  for epoch in range(num_epochs):\n",
        "    network.train()\n",
        "    timer.start()\n",
        "    for X, y in train_iter:\n",
        "      trainer.zer_grad()\n",
        "      X, y = X.to(devices[0]), y.to(devices[0])\n",
        "      l = loss(network(X), y)\n",
        "      l.backward()\n",
        "      trainer.step()\n",
        "    timer.stop()\n",
        "    # visualize steps with acceleration devices[0]\n",
        "  # same on the print statement and accuracy, with acceleration"
      ],
      "metadata": {
        "id": "NCqWr5jF3xKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try_gpu(i=0), num_gpu()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tByQRi24BJM",
        "outputId": "0de5cdad-af36-437e-99c0-4bd1bc07e463"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(device(type='cuda', index=0), 1)"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train(my_resnet, num_gpus=1, batch_size=256, lr=0.1)\n",
        "train(my_resnet, num_gpus=2, batch_size=256, lr=0.2)"
      ],
      "metadata": {
        "id": "M2d-s9gs4CDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parameter Servers"
      ],
      "metadata": {
        "id": "s6KcaLRVuXaL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scale = 0.01\n",
        "W1 = torch.randn(size=(20, 1, 3, 3)) * scale\n",
        "b1 = torch.zeros(20)\n",
        "W2 = torch.randn(size=(50, 20, 5, 5)) * scale\n",
        "b2 = torch.zeros(50)\n",
        "W3 = torch.randn(size=(100, 128)) * scale\n",
        "b3 = torch.zeros(128)\n",
        "W4 = torch.randn(size=(128, 10)) * scale\n",
        "b4 = torch.zeros(10)\n",
        "params = [W1, b1, W2, b2, W3, b3, W4, b4]"
      ],
      "metadata": {
        "id": "l__cEHt_eCbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Synchronization"
      ],
      "metadata": {
        "id": "2X5cGs9j4uti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_parameters(params, device):\n",
        "  new_params = [p.to(device) for p in params]\n",
        "  for p in new_params:\n",
        "    p.requires_grad_()\n",
        "  return new_params\n",
        "\n",
        "new_params = get_parameters(params, try_gpu(i=0))\n",
        "new_params[1], new_params[1].grad,"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvXKwypYn2x3",
        "outputId": "6f7c9822-182a-4218-a99a-80b47cd43e01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        device='cuda:0', requires_grad=True),\n",
              " None)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def allreduce(data):\n",
        "  for i in range(1, len(data)):\n",
        "    data[0][:] += data[i].to(data[0].device)\n",
        "\n",
        "  for i in range(1, len(data)):\n",
        "    data[i][:] = data[0].to(data[i].device)\n"
      ],
      "metadata": {
        "id": "6Pl6pjJWn26d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' use case with more than one gpu '''\n",
        "data = [torch.ones((1, 2), device=try_gpu(i=0)) for _ in range(2)]\n",
        "print(data[0], data[1])\n",
        "allreduce(data)\n",
        "print(data[0], data[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPVopfk_n2-L",
        "outputId": "b4db8e5c-3807-4981-9a01-e144a89a0d80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1.]], device='cuda:0') tensor([[1., 1.]], device='cuda:0')\n",
            "tensor([[2., 2.]], device='cuda:0') tensor([[2., 2.]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Distribute data"
      ],
      "metadata": {
        "id": "OTy1zvkM6lxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = torch.arange(20).reshape(4, 5)\n",
        "# devices = [torch.device('cuda:0'), torch.device('cuda:1')]\n",
        "devices = [torch.device('cuda:0')]\n",
        "split = nn.parallel.scatter(data, devices)\n",
        "data, devices, split"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxbKVOs0n3Bj",
        "outputId": "6de2642a-d30e-4ad7-cf58-581fe6568782"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0,  1,  2,  3,  4],\n",
              "         [ 5,  6,  7,  8,  9],\n",
              "         [10, 11, 12, 13, 14],\n",
              "         [15, 16, 17, 18, 19]]),\n",
              " [device(type='cuda', index=0)],\n",
              " (tensor([[ 0,  1,  2,  3,  4],\n",
              "          [ 5,  6,  7,  8,  9],\n",
              "          [10, 11, 12, 13, 14],\n",
              "          [15, 16, 17, 18, 19]], device='cuda:0'),))"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_batch(X, y, devices):\n",
        "  return (nn.parallel.scatter(X, devices), nn.parallel.scatter(y, devices))"
      ],
      "metadata": {
        "id": "V6EZ8AEd6qDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "xDjD0sZ26oSb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' training function '''\n",
        "loss = nn.CrossEntropyLoss(reduction='none')\n",
        "def train_batch(X, y, device_params, devices, lr):\n",
        "  X_shards, y_shards = split_batch(X, y, devices)\n",
        "  # loss calculated separately on each gpu\n",
        "  loss_ = [loss(network(X_shard, device_W), y_shard).sum()\n",
        "        for X_shard, y_shard, device_W\n",
        "            in zip(X_shards, y_shards, device_params)]\n",
        "  # backpropagation performed separately on each gpu\n",
        "  for l in loss_:\n",
        "    l.backward()\n",
        "  # summ all gradients from each gpu and brodcast- one operation\n",
        "  with torch.no_grad():\n",
        "    for i in range(len(device_params[0])):\n",
        "      allreduce([device_params[c][i].grad for c in range(len(device_params))])\n",
        "  # model parameters updated separately on each gpu\n",
        "  for param in device_params:\n",
        "    SGD(param, lr, X.shape[0])"
      ],
      "metadata": {
        "id": "giKbCxr_n3FP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' Train loop\n",
        "in the train loop, for each X, y perform gpu training on minibatch, and add synchronization\n",
        "\n",
        "train_batch(X, y, device_params, devices, lr)\n",
        "torch.cuda.synchronize()\n",
        "'''"
      ],
      "metadata": {
        "id": "XcGjdRhg6pk3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}